# transformer_from_scratch

The following repo is an attempt to reproduce the results/outcomes from the paper "Attention is all you need". The transformer is implemented from scratch using Pytorch/Python and no other high level API(nn.Transformer etc.). The model is trained on a corpus of English-Italian dataset for Machine Translation.

![image](https://github.com/user-attachments/assets/30648bce-a5bf-470d-9062-6398d3172354)


## this is just the model arcitecture in this repo, no training code included.
